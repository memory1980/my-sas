import pandas as pd
import os
from datetime import datetime

def analyze_stocks_single_period(
    codes,                    # è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¿…é¡»ï¼‰
    input_dir=None,           # æ•°æ®ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•/dataï¼‰
    period='M',               # åˆ†æå‘¨æœŸï¼š'M'æœˆçº¿ï¼Œ'W'å‘¨çº¿ï¼Œ'D'æ—¥çº¿ï¼ˆé»˜è®¤'M'ï¼‰
    threshold=5,              # turnå€æ•°é˜ˆå€¼ï¼Œé»˜è®¤5å€
    window_n=None,            # å‰ååˆ†æå‘¨æœŸæ•°
    base_n=None,              # åŸºå‡†ç‚¹æ•°é‡
    close_n=None,             # closeåˆ†æçª—å£
    save_csv=True,            # æ˜¯å¦ä¿å­˜CSV
    output_dir=None           # è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
):
    """
    åˆ†æå•å‘¨æœŸçš„è‚¡ç¥¨turnæ¨¡å¼
    æ¯ä¸ªåŸºå‡†ç‚¹ç‹¬ç«‹å±•ç¤ºï¼Œåé¢è·Ÿç€æ‰¾åˆ°çš„é«˜turnç‚¹å’Œæœ€ä½closeç‚¹
    """
    
    # å‘¨æœŸé»˜è®¤å‚æ•°é…ç½®
    period_config = {
        'M': {'name': 'æœˆçº¿', 'window_n': 10, 'base_n': 10, 'close_n': 20, 'filename': 'stock_data_M.csv'},
        'W': {'name': 'å‘¨çº¿', 'window_n': 15, 'base_n': 20, 'close_n': 30, 'filename': 'stock_data_W.csv'},
        'D': {'name': 'æ—¥çº¿', 'window_n': 30, 'base_n': 50, 'close_n': 60, 'filename': 'stock_data_D.csv'}
    }
    
    if period not in period_config:
        raise ValueError(f"periodå¿…é¡»æ˜¯ 'M','W','D' ä¹‹ä¸€")
    
    config = period_config[period]
    window_n = window_n or config['window_n']
    base_n = base_n or config['base_n']
    close_n = close_n or config['close_n']
    filename = config['filename']
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    # è®¾ç½®æ•°æ®ç›®å½•ï¼ˆå¦‚æœæœªæä¾›ï¼Œä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•/dataï¼‰
    if input_dir is None:
        data_dir = os.path.join(project_root, "data")
    elif os.path.isabs(input_dir):
        data_dir = input_dir
    else:
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºè„šæœ¬ä½ç½®
        script_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.abspath(os.path.join(script_dir, input_dir))
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    file_path = os.path.join(data_dir, filename)
    abs_file_path = os.path.abspath(file_path)
    
    # è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæœªæä¾›ï¼Œä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•/anarsï¼‰
    if output_dir is None:
        output_dir = os.path.join(project_root, "anars")
    elif not os.path.isabs(output_dir):
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºè„šæœ¬ä½ç½®
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_dir = os.path.abspath(os.path.join(script_dir, output_dir))
    
    print("="*70)
    print(f"ğŸ“Š {config['name']}æ•°æ®åˆ†æ")
    print("="*70)
    print(f"ğŸ“‹ è‚¡ç¥¨æ•°é‡: {len(codes)}")
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {abs_file_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ¯ turné˜ˆå€¼: {threshold}å€")
    print(f"ğŸ“ˆ åˆ†æå‚æ•°: å‰å{window_n}å‘¨æœŸ, å–{base_n}ä¸ªåŸºå‡†ç‚¹, closeçª—å£{close_n}")
    print("="*70)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(abs_file_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {abs_file_path}")
        return pd.DataFrame()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    try:
        data = pd.read_csv(abs_file_path, encoding='utf-8-sig')
        print(f"âœ… æˆåŠŸåŠ è½½: {len(data)} è¡Œæ•°æ®")
    except Exception as e:
        print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()
    
    # åˆ†ææ•°æ®
    summary_results = []
    all_extracted_data = []
    
    for code in codes:
        # ç­›é€‰è‚¡ç¥¨æ•°æ®
        df = data[data['code'] == code].sort_values('date')
        
        if len(df) < base_n:
            print(f"  âš ï¸  {code}: æ•°æ®ä¸è¶³ï¼ˆéœ€è¦{base_n}ï¼Œå®é™…{len(df)}ï¼‰")
            continue
        
        print(f"  ğŸ“ˆ åˆ†æ: {code} ({len(df)}ä¸ªæ•°æ®ç‚¹)")
        
        # å–æœ€å°çš„base_nä¸ªå€’æ•°æ—¥æœŸä½œä¸ºåŸºå‡†ç‚¹
        last_points = df.nlargest(base_n, 'date')
               
        
        base_points = last_points 
        
        print(base_points.head())
        
        base_count = 0
        found_count = 0
        
        for _, row in base_points.iterrows():
            base_count += 1
            pos = df.index.get_loc(row.name)
            base_turn = row['date']
            base_idx = row.name
            
            # 1. è·å–é«˜turnç‚¹indices
            window = df.iloc[pos:min(len(df), pos+window_n+1)]
            high_turn_mask = window['turn'] >= base_turn * threshold
            high_turn_mask = high_turn_mask & (window.index != base_idx)  # æ’é™¤åŸºå‡†ç‚¹æœ¬èº«
            high_turn_indices = window[high_turn_mask].index.tolist()
            
            # 2. è·å–æœ€ä½closeç‚¹index
            close_window = df.iloc[pos:min(len(df), pos+close_n+1)]
            min_close_idx = close_window['close'].idxmin() if not close_window.empty else None
            
            # 3. æ„å»ºè¿™ä¸ªåŸºå‡†ç‚¹çš„æ‰€æœ‰ç›¸å…³ç´¢å¼•
            # åŸºå‡†ç‚¹å¿…é¡»æ’åœ¨ç¬¬ä¸€ä½ï¼Œç„¶åæ˜¯å®ƒçš„é«˜turnç‚¹ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰ï¼Œæœ€åæ˜¯æœ€ä½closeç‚¹
            indices_for_this_base = [base_idx]  # åŸºå‡†ç‚¹æ€»æ˜¯ç¬¬ä¸€ä¸ª
            
            # æŒ‰æ—¶é—´é¡ºåºæ’åˆ—é«˜turnç‚¹
            if high_turn_indices:
                found_count += 1
                high_turn_dates = data.loc[high_turn_indices, 'date']
                high_turn_indices_sorted = [idx for idx, _ in sorted(zip(high_turn_indices, high_turn_dates), 
                                                                    key=lambda x: x[1])]
                indices_for_this_base.extend(high_turn_indices_sorted)
            
            # æ·»åŠ æœ€ä½closeç‚¹ï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸åœ¨åˆ—è¡¨ä¸­ï¼‰
            if min_close_idx and min_close_idx not in indices_for_this_base:
                indices_for_this_base.append(min_close_idx)
            
            # 4. æå–è¿™ä¸ªåŸºå‡†ç‚¹çš„æ‰€æœ‰ç›¸å…³æ•°æ®
            extracted_df = data.loc[indices_for_this_base].copy()
            
            # 5. æ·»åŠ æ ‡è®°ä¿¡æ¯
            extracted_df['æ ‡è®°'] = 'å…¶ä»–'
            extracted_df.loc[base_idx, 'æ ‡è®°'] = 'åŸºå‡†ç‚¹'
            
            for idx in high_turn_indices:
                if idx in extracted_df.index:
                    extracted_df.loc[idx, 'æ ‡è®°'] = 'é«˜turnç‚¹'
            
            if min_close_idx and min_close_idx in extracted_df.index:
                if extracted_df.loc[min_close_idx, 'æ ‡è®°'] == 'å…¶ä»–':
                    extracted_df.loc[min_close_idx, 'æ ‡è®°'] = 'æœ€ä½closeç‚¹'
            
            # 6. æ·»åŠ åŸºå‡†ä¿¡æ¯ï¼ˆæ‰€æœ‰è¡Œéƒ½åŠ ä¸Šç›¸åŒçš„åŸºå‡†ä¿¡æ¯ï¼‰
            extracted_df['åŸºå‡†æ—¥æœŸ'] = row['date']
            extracted_df['åŸºå‡†turnå€¼'] = base_turn
            extracted_df['åŸºå‡†è‚¡ç¥¨'] = code
            extracted_df['åŸºå‡†å‘¨æœŸ'] = config['name']
            extracted_df['é˜ˆå€¼å€æ•°'] = threshold
            extracted_df['é«˜turnç‚¹æ•°é‡'] = len(high_turn_indices)
            extracted_df['åˆ†æèŒƒå›´(å‰å)'] = f"Â±{window_n}å‘¨æœŸ"
            
            # 7. æ·»åŠ ç›¸å¯¹turnå€æ•°ï¼ˆé«˜turnç‚¹ç›¸å¯¹äºåŸºå‡†ç‚¹çš„å€æ•°ï¼‰
            for idx in extracted_df.index:
                if idx != base_idx:  # ä¸æ˜¯åŸºå‡†ç‚¹
                    current_turn = extracted_df.loc[idx, 'turn']
                    relative_multiple = current_turn / base_turn if base_turn > 0 else 0
                    extracted_df.loc[idx, 'ç›¸å¯¹äºåŸºå‡†turnå€æ•°'] = round(relative_multiple, 2)
                else:
                    extracted_df.loc[idx, 'ç›¸å¯¹äºåŸºå‡†turnå€æ•°'] = 1.0
            
            # 8. ä¿å­˜åˆ°åˆ—è¡¨
            columns_to_keep = [   'code', 'date','high','low','close', 'turn','volume',  'æ ‡è®°', 'åŸºå‡†æ—¥æœŸ', 'åŸºå‡†turnå€¼', 'åŸºå‡†å‘¨æœŸ' ]

            all_extracted_data.append(extracted_df[columns_to_keep])
            
            all_extracted_data.append(extracted_df)
       
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            summary_results.append({
                'è‚¡ç¥¨ä»£ç ': code,
                'å‘¨æœŸ': config['name'],
                'åŸºå‡†æ—¥æœŸ': row['date'],
                'åŸºå‡†turn': round(base_turn, 6),
                'é˜ˆå€¼å€æ•°': threshold,
                'é«˜turnç‚¹æ•°': len(high_turn_indices),
                'é«˜turnç‚¹æƒ…å†µ': 'æœ‰' if high_turn_indices else 'æ— ',
                'æœ€ä½closeæ—¥æœŸ': close_window.loc[min_close_idx, 'date'] if min_close_idx else None,
                'æœ€ä½closeä»·æ ¼': round(close_window.loc[min_close_idx, 'close'], 4) if min_close_idx else None,
                'åˆ†æèŒƒå›´': f"Â±{window_n}å‘¨æœŸ"
            })
        
        print(f"    åˆ†æå®Œæˆ: {base_count}ä¸ªåŸºå‡†ç‚¹ä¸­ï¼Œ{found_count}ä¸ªæ‰¾åˆ°äº†é«˜turnç‚¹")
    
    # æ±‡æ€»ç»“æœ
    summary_df = pd.DataFrame(summary_results)
 
    # ä¿å­˜æå–çš„æ•°æ®æ–‡ä»¶
    if all_extracted_data and save_csv:
        # ç›´æ¥åˆå¹¶æ‰€æœ‰æ•°æ®
        final_extracted_df = pd.concat(all_extracted_data, ignore_index=False)
        
        timestamp = datetime.now().strftime("%Y%m%d%H%M")
        extracted_file = os.path.join(output_dir, f"{config['name']}è¯¦ç»†ç»“æœ_{timestamp}.csv")
        final_extracted_df.to_csv(extracted_file, index=True, encoding='utf-8-sig')
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: {extracted_file}")
        print(f"ğŸ“Š æ€»è¡Œæ•°: {len(final_extracted_df)} è¡Œ")
    elif save_csv and not all_extracted_data:
        print(f"\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®ï¼Œä¸ç”Ÿæˆæå–æ•°æ®æ–‡ä»¶")
 
    return summary_df, all_extracted_data if all_extracted_data else []

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
   
    # 1. å…ˆè·å–é¡¹ç›®è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    input_dir = os.path.join(project_root, "data")
    output_dir = os.path.join(project_root, "anars")
    
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“‚ é»˜è®¤æ•°æ®ç›®å½•: {input_dir}")
    print(f"ğŸ“‚ é»˜è®¤è¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # 2. å¯¼å…¥è‚¡ç¥¨åˆ—è¡¨
    from high_growth_stock_list import high_growth_stocks
    
    # 3. åˆ†æç¤ºä¾‹ - ç›´æ¥ä¿®æ”¹è¿™é‡Œçš„å‚æ•°
    print("\n" + "="*70)
    print("ğŸ“ˆ å¼€å§‹åˆ†æ - è¯·åœ¨ä¸‹æ–¹ä¿®æ”¹å‚æ•°")
    print("="*70)
    
    stock_list = high_growth_stocks[:]  # æµ‹è¯•3åªè‚¡ç¥¨ï¼Œå¯ä»¥ä¿®æ”¹ä¸ºæ›´å¤š
    
    # åœ¨è¿™é‡Œç›´æ¥ä¿®æ”¹å‚æ•°
    results_month, details_month= analyze_stocks_single_period(
        codes=stock_list,
        period='M',           # 'M'æœˆçº¿, 'W'å‘¨çº¿, 'D'æ—¥çº¿
        threshold=5,          # è°ƒæ•´é˜ˆå€¼å€æ•°
        window_n=5,          # è°ƒæ•´å‰åæŸ¥æ‰¾èŒƒå›´
        base_n=1,            # è°ƒæ•´åŸºå‡†ç‚¹æ•°é‡
        close_n=5,           # è°ƒæ•´closeçª—å£
        save_csv=True,
        output_dir=output_dir
    )
    
    print("\n" + "="*70)
    print("âœ… åˆ†æå®Œæˆ")
    print("="*70)
    print("ğŸ“ å‚æ•°è¯´æ˜:")
    print("   threshold: é˜ˆå€¼å€æ•°ï¼Œå¦‚5è¡¨ç¤ºæ‰¾5å€ä»¥ä¸Šçš„turn")
    print("   window_n: å‰åæŸ¥æ‰¾èŒƒå›´ï¼Œå¦‚12è¡¨ç¤ºå‰å12ä¸ªæœˆ")
    print("   base_n: åŸºå‡†ç‚¹æ•°é‡ï¼Œå–æœ€å°çš„nä¸ªturnå€¼ä½œä¸ºåŸºå‡†")
    print("   close_n: æ‰¾æœ€ä½closeç‚¹çš„çª—å£")
    print("="*70)
    
    # results_month, details_month = analyze_stocks_single_period(
    #     codes=stock_list,
    #     period='W',           # 'M'æœˆçº¿, 'W'å‘¨çº¿, 'D'æ—¥çº¿
    #     threshold=5,          # è°ƒæ•´é˜ˆå€¼å€æ•°
    #     window_n=10,          # è°ƒæ•´åæŸ¥æ‰¾èŒƒå›´
    #     base_n=10,            # è°ƒæ•´åŸºå‡†ç‚¹æ•°é‡
    #     close_n=10,           # è°ƒæ•´closeçª—å£
    #     save_csv=True,
    #     output_dir=output_dir
    # )
    
    
    # print("\n" + "="*70)
    # print("âœ… åˆ†æå®Œæˆ")
    # print("="*70)
    # print("ğŸ“ å‚æ•°è¯´æ˜:")
    # print("   threshold: é˜ˆå€¼å€æ•°ï¼Œå¦‚5è¡¨ç¤ºæ‰¾5å€ä»¥ä¸Šçš„turn")
    # print("   window_n: å‰åæŸ¥æ‰¾èŒƒå›´ï¼Œå¦‚12è¡¨ç¤ºå‰å12ä¸ªæœˆ")
    # print("   base_n: åŸºå‡†ç‚¹æ•°é‡ï¼Œå–æœ€å°çš„nä¸ªturnå€¼ä½œä¸ºåŸºå‡†")
    # print("   close_n: æ‰¾æœ€ä½closeç‚¹çš„çª—å£")
    # print("="*70)
  
    # results_month, details_month = analyze_stocks_single_period(
    #     codes=stock_list,
    #     period='D',           # 'M'æœˆçº¿, 'W'å‘¨çº¿, 'D'æ—¥çº¿
    #     threshold=5,          # è°ƒæ•´é˜ˆå€¼å€æ•°
    #     window_n=60,          # è°ƒæ•´åæŸ¥æ‰¾èŒƒå›´
    #     base_n=10,            # è°ƒæ•´åŸºå‡†ç‚¹æ•°é‡
    #     close_n=60,           # è°ƒæ•´closeçª—å£
    #     save_csv=True,
    #     output_dir=output_dir
    # )
    
    
    # print("\n" + "="*70)
    # print("âœ… åˆ†æå®Œæˆ")
    # print("="*70)
    # print("ğŸ“ å‚æ•°è¯´æ˜:")
    # print("   threshold: é˜ˆå€¼å€æ•°ï¼Œå¦‚5è¡¨ç¤ºæ‰¾5å€ä»¥ä¸Šçš„turn")
    # print("   window_n: å‰åæŸ¥æ‰¾èŒƒå›´ï¼Œå¦‚12è¡¨ç¤ºå‰å12ä¸ªæœˆ")
    # print("   base_n: åŸºå‡†ç‚¹æ•°é‡ï¼Œå–æœ€å°çš„nä¸ªturnå€¼ä½œä¸ºåŸºå‡†")
    # print("   close_n: æ‰¾æœ€ä½closeç‚¹çš„çª—å£")
    # print("="*70)
    